# 钢卷性能预测 - 神经网络模型

## 项目概述

本模块专注于使用深度学习方法（TabNet、MLP、NODE、TabTransformer）对钢卷性能指标进行预测建模。通过神经网络强大的非线性建模能力，捕捉复杂的特征交互关系，并提供可解释的特征重要性分析。

## 最终结果保存位置

- **模型性能汇总**: `results/01_tabnet_results/performance_summary.csv` - TabNet模型的交叉验证性能指标
- **训练好的模型**: `results/*/saved_models/` - 保存的模型文件（.joblib和.zip格式）
- **特征重要性**: `results/*/` 文件夹中的特征重要性图表和CSV文件
- **扰动预测结果**: `results/*/` 文件夹中的PDP图表和预测结果CSV文件
- **超参数搜索结果**: `results/*/` 文件夹中的超参数搜索记录

## 代码文件详细说明

### 1. 01a_tabnet_modeling.py - TabNet建模

**功能**: 使用TabNet深度神经网络进行性能预测建模

**输入文件**:
- `../01_read_data/results/04_data_selected.xlsx` - 经过特征筛选的最终数据集

**输出文件**:
- `results/01_tabnet_results/` - TabNet模型结果文件夹
- `saved_models/` - 训练好的TabNet模型（.joblib和.zip格式）
- `*_feature_importance.png/csv` - 特征重要性分析
- `*_hparam_search.csv` - 超参数搜索结果
- `performance_summary.csv` - 模型性能汇总

**主要功能**:
- 使用TabNet深度神经网络进行表格数据建模
- 引入StandardScaler进行数据标准化
- 使用Pipeline将Scaler和TabNetRegressor捆绑
- 随机搜索多组超参数，以R²均值选择最佳组合
- 5折交叉验证评估TabNet模型性能
- 提取TabNet内置的feature_importances_作为特征重要性
- 支持GPU加速训练（如果可用）
- 保存模型权重和Pipeline供后续使用

### 2. 01b_tabnet_perturbation_predict.py - TabNet扰动预测

**功能**: 使用训练好的TabNet模型对扰动数据进行预测分析

**输入文件**:
- `results/01_tabnet_results/saved_models/` - 训练好的TabNet模型
- `../01_read_data/results/05_perturbed_dataset_*.csv` - 扰动数据集

**输出文件**:
- `01b_tabnet_prediction_results_*.csv` - 详细预测结果（ICE数据）
- `01b_tabnet_summary_stats_*.csv` - 统计汇总结果（PDP数据）
- `01b_pdp_plot_*.png` - 部分依赖图（PDP效应图）

**主要功能**:
- 加载训练好的TabNet Pipeline和模型权重
- 清洗扰动数据，移除全为NaN或0的行，用0填充剩余NaN
- 使用TabNet Pipeline对清洗后的数据集进行批量预测
- 生成个体条件期望（ICE）和部分依赖图（PDP）分析
- 绘制带90%置信区间的PDP效应图
- 分析关键工艺参数对性能指标的影响趋势

## 神经网络模型特点

### TabNet模型优势
- **可解释性**: 内置注意力机制，提供特征重要性分析
- **表格数据专用**: 专门为表格数据设计的神经网络架构
- **特征选择**: 自动学习最重要的特征组合
- **端到端训练**: 无需手工特征工程
- **可解释性**: 提供特征重要性和注意力权重

### 模型架构特点
- **注意力机制**: 学习特征之间的交互关系
- **残差连接**: 解决深度网络的梯度消失问题
- **批标准化**: 加速训练收敛
- **Dropout**: 防止过拟合

## 超参数调优策略

### TabNet关键超参数
- **n_d/n_a**: 决策层和注意力层的维度
- **n_steps**: 决策步数
- **gamma**: 稀疏性正则化参数
- **lambda_sparse**: 稀疏性损失权重
- **optimizer_params**: 优化器参数
- **scheduler_params**: 学习率调度器参数

### 搜索策略
- **随机搜索**: 在预定义的参数空间中进行随机搜索
- **交叉验证**: 使用5折交叉验证评估参数组合
- **早停机制**: 防止过拟合，提高泛化能力
- **学习率调度**: 动态调整学习率

## 特征重要性分析

### TabNet特征重要性
- **内置重要性**: 使用TabNet内置的feature_importances_属性
- **注意力权重**: 分析注意力机制学习到的特征权重
- **决策路径**: 可视化特征在决策过程中的作用
- **交互分析**: 分析特征之间的交互关系

## 扰动预测分析

通过PDP（部分依赖图）分析关键工艺参数对性能指标的影响：
- **热点峰值温度**: 分析最高温度点对性能的影响
- **冷点峰值温度**: 分析最低温度点对性能的影响
- **保温时长**: 分析保温时间对性能的影响

## 模型性能评估

TabNet模型会生成详细的性能评估报告，包括：
- **R²分数**: 决定系数，衡量模型解释方差的能力
- **MAE**: 平均绝对误差
- **RMSE**: 均方根误差
- **交叉验证结果**: 5折交叉验证的均值和标准差
- **超参数搜索记录**: 记录所有尝试的参数组合和对应性能

## 技术实现细节

### 数据预处理
- **标准化**: 使用StandardScaler进行特征标准化
- **类型转换**: 确保数据为np.float32类型（TabNet要求）
- **缺失值处理**: 用0填充NaN值
- **数据清洗**: 移除全为NaN或0的行

### 模型训练
- **并行控制**: 限制CPU核心数避免资源冲突
- **GPU支持**: 自动检测并使用GPU加速（如果可用）
- **早停机制**: 防止过拟合
- **模型保存**: 同时保存Pipeline和模型权重

### 预测分析
- **批量预测**: 高效处理大量扰动数据
- **置信区间**: 提供预测的不确定性估计
- **可视化**: 生成直观的PDP效应图

## 扩展模型支持

本模块还预留了其他神经网络模型的接口：
- **MLP**: 多层感知机
- **NODE**: 神经普通微分方程
- **TabTransformer**: 基于Transformer的表格数据模型

## 注意事项

- 请确保已运行01_read_data模块生成最终数据集
- TabNet需要PyTorch环境，请确保已安装相关依赖
- 建议使用GPU进行训练以加速计算
- 扰动预测需要先生成扰动数据集（01_read_data模块的05脚本）
- 所有模型都设置了随机种子确保结果可复现
- TabNet模型训练时间较长，建议在性能较好的机器上运行
- 模型文件较大，注意磁盘空间管理
