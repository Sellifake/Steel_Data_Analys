# 钢卷温度曲线数据处理流程

## 项目概述

本项目是一个完整的钢卷温度曲线数据处理流程，主要用于从原始Excel文件中提取、清洗、分析钢卷的温度曲线数据，并计算相关的工艺特征。整个流程分为5个主要步骤，最终生成可用于机器学习建模的干净数据集和扰动数据集。

## 数据量变化统计

| 步骤        | 输入数据量     | 输出数据量        | 主要操作                   |
| ----------- | -------------- | ----------------- | -------------------------- |
| 01_预处理   | 12737个钢卷    | 12737个钢卷       | 数据清洗和格式统一         |
| 02_特征提取 | 12737个钢卷    | 3250条工艺记录    | 去重处理，保留唯一工艺记录 |
| 03_数据合并 | 3250条工艺记录 | 2760行有效数据    | 合并性能数据，清洗无效数据 |
| 04_特征选择 | 2760行，74列   | 2760行，31列      | 删除43个冗余特征           |
| 05_扰动生成 | 2760行，31列   | 449,880个扰动样本 | 生成敏感性分析数据         |

**关键数据节点**:

- **原始数据**: 12,737个钢卷的时间序列数据
- **工艺特征**: 3,250条唯一工艺记录
- **最终数据集**: 2,760行，31列（27个特征 + 3个性能指标 + 1个ID）
- **扰动数据集**: 449,880个样本（热点/冷点峰值温度各57,960个，保温时长333,960个）

## 最终结果保存位置

- **主要数据文件**: `results/04_data_selected.xlsx` - 最终可用于建模的干净数据集
- **扰动数据集**: `results/05_perturbed_dataset_*.csv` - 用于敏感性分析的扰动数据集
- **中间数据文件**: `results/03_merged_data.xlsx` - 合并了工艺特征、化学成分和性能指标的完整数据集
- **工艺特征数据**: `results/extract_data.xlsx` - 从温度曲线中提取的工艺特征
- **预处理数据**: `all_coils_data.parquet` - 预处理后的原始时间序列数据

## 代码文件详细说明

### 1. 01_preprocess_data.py - 数据预处理

**功能**: 从原始Excel文件中提取和清洗钢卷时间序列数据

**输入文件**:

- `data_origin/` 文件夹中的所有Excel文件（温度曲线数据）

**输出文件**:

- `all_coils_data.parquet` - 预处理后的合并数据文件

**主要功能**:

- 遍历 `data_origin`文件夹下的所有Excel文件
- 从每个工作表中提取钢卷的时间序列数据
- 进行数据清洗：统一列名、处理重复列、转换数据类型、去除无效数据
- 基于钢卷号去重，确保每个钢卷只处理一次
- 将所有清洗后的数据合并保存为Parquet格式

**数据量统计**:

- 处理了12737个钢卷的时间序列数据
- 生成预处理后的合并数据文件

### 2. 02_read_data.py - 特征提取

**功能**: 从时间序列数据中计算工艺特征

**输入文件**:

- `all_coils_data.parquet` - 预处理后的时间序列数据

**输出文件**:

- `results/extract_data.xlsx` - 提取的工艺特征数据
- `steel_coil_ids.txt` - 所有有效钢卷号列表
- `钢卷编号/steel_coil_ids_1.txt` 到 `steel_coil_ids_9.txt` - 分割后的钢卷号文件

**主要功能**:

- 读取预处理后的Parquet文件
- 对每个钢卷的温度曲线进行三阶段划分（升温、保温、降温）
- 计算详细的工艺特征：各阶段时长、温升/温降幅度、平均速率、峰值温度等
- 计算热点和冷点之间的差异特征
- 对特征进行去重处理
- 将钢卷号分割成多个小文件便于分批处理

**数据量统计**:

- 处理了12737个钢卷的时间序列数据
- 去重后保留3250条唯一工艺记录
- 生成9个分割后的钢卷号文件

### 3. 03_merge_clean_and_eda.py - 数据合并与探索性分析

**功能**: 合并化学成分和性能数据，进行初步清洗和探索性分析

**输入文件**:

- `results/extract_data.xlsx` - 工艺特征数据
- `performance/` 文件夹中的所有Excel文件 - 性能与化学成分数据

**输出文件**:

- `results/03_merged_data.xlsx` - 合并后的完整数据集
- `results/03_correlation_heatmap.png` - 相关性热力图
- `results/03_correlation_matrix.csv` - 相关性矩阵
- `results/03_vif_scores.csv` - VIF分数
- `results/03_eda_plots/` 文件夹 - 分布直方图和散点图

**主要功能**:

- 加载工艺特征数据作为基准
- 从performance文件夹读取性能和化学成分数据
- 以工艺特征为基准进行左合并
- 强制类型转换，确保所有列都为数值类型
- 进行基础数据清洗：删除无效数据、处理缺失值
- 按"工艺特征→化学成分→性能指标"顺序重新排列列
- 进行全面的探索性分析：相关性分析、VIF分析、分布图、散点图

**数据量统计**:

- 基准数据集：3250条工艺记录
- 性能数据：18549行原始记录，去重后2988行唯一钢卷记录
- 合并后数据集：3250行，74列
- 数据清洗：移除490行无效数据（冷点峰值温度为0：249行，化学成分全为0：238行，目标变量缺失：3行）
- 最终有效数据：2760行，74列

### 4. 04_feature_analysis.py - 特征选择与最终清理

**功能**: 进行特征选择、离群点检测和最终的数据清理

**输入文件**:

- `results/03_merged_data.xlsx` - 合并后的完整数据集

**输出文件**:

- `results/04_data_selected.xlsx` - 最终清理后的数据集
- `results/04_correlation_heatmap.png` - 最终相关性热力图
- `results/04_correlation_matrix.csv` - 最终相关性矩阵
- `results/04_vif_scores.csv` - 最终VIF分数
- `results/04_eda_plots/` 文件夹 - 最终分布图和散点图

**主要功能**:

- 根据预定义列表手动删除指定特征
- 执行两阶段离群点检测：
  - IQR方法移除极端单维离群点
  - Isolation Forest算法检测多维离群点
- 对清理后的数据重新进行EDA分析
- 生成最终可用于建模的干净数据集

**数据量统计**:

- 输入数据：2760行，74列
- 特征删除：移除43个指定特征
- 最终数据集：2760行，31列（27个输入特征 + 3个性能指标 + 1个ID列）
- 离群点检测：已跳过（ENABLE_OUTLIER_DETECTION=False）

### 5. 05_generate_perturbed_data.py - 扰动数据生成

**功能**: 生成用于敏感性分析的扰动数据集

**输入文件**:

- `results/04_data_selected.xlsx` - 最终清理后的数据集

**输出文件**:

- `results/05_perturbed_dataset_热点_峰值温度.csv` - 热点峰值温度扰动数据集
- `results/05_perturbed_dataset_冷点_峰值温度.csv` - 冷点峰值温度扰动数据集
- `results/05_perturbed_dataset_保温时长.csv` - 保温时长扰动数据集

**主要功能**:

- 加载最终清理后的数据集作为基准
- 针对三个关键工艺参数生成扰动数据集：
  - **热点峰值温度**: 在原始值基础上从-10°C到+10°C变化，步长1°C
  - **冷点峰值温度**: 在原始值基础上从-10°C到+10°C变化，步长1°C
  - **保温时长**: 在原始值基础上从-3600秒到+3600秒变化，步长60秒
- 使用向量化操作高效生成大规模扰动数据
- 对每个原始样本生成多个扰动变体，用于ICE（个体条件期望）分析
- 进行数据清洗：删除全为0或空的行，用0填充剩余NaN值
- 为后续的PDP（部分依赖图）分析提供数据支持

**数据量统计**:

- 基准数据集：2760行，31列（27个特征）
- 热点峰值温度扰动：2760 × 21 = 57,960个样本
- 冷点峰值温度扰动：2760 × 21 = 57,960个样本
- 保温时长扰动：2760 × 121 = 333,960个样本
- 总扰动样本数：449,880个样本

## 数据流程总结

1. **原始数据** → **预处理** → **特征提取** → **数据合并** → **特征选择** → **扰动数据生成**
2. 整个流程从原始Excel文件开始，经过多轮清洗和特征工程，最终生成包含工艺特征、化学成分和性能指标的完整数据集
3. 每个步骤都包含详细的数据质量检查和可视化分析
4. 最终数据集可用于后续的机器学习建模工作
5. 扰动数据集为敏感性分析和PDP（部分依赖图）分析提供数据支持

## 扰动数据生成原理

### ICE（个体条件期望）分析

- **基础**: 以原始数据中的每一条记录作为基准
- **扰动**: 选择一个特征（如'热点_峰值温度'）
- **范围**: 针对该特征，生成一个扰动值数组（如[-10, -9, ..., +10]）
- **生成**: 对每条记录应用所有扰动值，保持其他特征不变
- **结果**: 每个被扰动的特征都会生成一个N×M行的新数据集

### 扰动参数配置

- **热点峰值温度**: 从-10°C到+10°C，步长1°C（21个扰动点）
- **冷点峰值温度**: 从-10°C到+10°C，步长1°C（21个扰动点）
- **保温时长**: 从-3600秒到+3600秒，步长60秒（121个扰动点）

## 注意事项

- 请按照代码顺序依次运行：01 → 02 → 03 → 04 → 05
- 每个步骤都会生成相应的中间结果和可视化图表，便于数据质量检查
